{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a3ef25d",
   "metadata": {},
   "source": [
    "## 0. Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "027d869f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import SGD\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import requests\n",
    "import pyreadr\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace55d0b",
   "metadata": {},
   "source": [
    "## 1. Implement a TARNet for predicting Conditional Average Treatment Effects (CATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "123649bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TarNet(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(TarNet, self).__init__()\n",
    "        \n",
    "        self.input_dim = input_dim \n",
    "        \n",
    "        #Representation phi\n",
    "        self.phi = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, 256),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ELU()\n",
    "        )\n",
    "        \n",
    "        self.treatment = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        #Layer of factual and counter factural\n",
    "        self.y0 = nn.Sequential(\n",
    "            nn.Linear(256, 64),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(64, 1) \n",
    "        )\n",
    "        \n",
    "        self.y1 = nn.Sequential(\n",
    "            nn.Linear(256, 64), \n",
    "            nn.ELU(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "          \n",
    "    def forward(self, inputs):\n",
    "        phi = self.phi(inputs)\n",
    "        \n",
    "        t_hat = self.treatment(inputs)\n",
    "        y0_hat = self.y0(phi)\n",
    "        y1_hat = self.y1(phi)\n",
    "                \n",
    "        out = torch.cat((y0_hat, y1_hat, t_hat), 1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac191c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lossFunc(y_true, t_true, predictions):\n",
    "    y = y_true.reshape(-1,1)\n",
    "    t = t_true.reshape(-1,1)\n",
    "    \n",
    "    y0_hat = predictions[:,0].reshape(-1,1)\n",
    "    y1_hat = predictions[:,1].reshape(-1,1)\n",
    "    \n",
    "    loss = torch.sum((1-t)*(y-y0_hat)**2) + torch.sum(t * (y-y1_hat)**2)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42c9433",
   "metadata": {},
   "source": [
    "## 2. Implement the IHDP dataset with response surface B as described in Bayesian Nonparametric Modeling for Causal Inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c333c50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def response_surface_B(t, X):\n",
    "    #Offset matrix\n",
    "    W = np.ones(X.shape)*0.5\n",
    "\n",
    "    #Regression vector\n",
    "    vals = [0, 0.1, 0.2, 0.3, 0.4]\n",
    "    probabilities = [0.6, 0.1, 0.1, 0.1, 0.1]\n",
    "    \n",
    "    np.random.seed(4)\n",
    "    beta_B = np.random.choice(vals, X.shape[1], p = probabilities)\n",
    "\n",
    "    mean_y0 = np.exp(np.dot((X+W), beta_B))\n",
    "    sigma_y0 = 1\n",
    "\n",
    "    mean_y1 = np.dot(X, beta_B)-15\n",
    "    sigma_y1 = 1\n",
    "\n",
    "    y0 = np.random.normal(mean_y0).reshape(-1, 1)\n",
    "    y1 = np.random.normal(mean_y1).reshape(-1, 1)\n",
    "    \n",
    "    y = (1-t)*y0 + t*y1\n",
    "    \n",
    "    return y, y0, y1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018ef0a2",
   "metadata": {},
   "source": [
    "## 3. Generate 10 random train / valid / and test splits of the IHDP dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04504906",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fetch raw data from github\n",
    "res = requests.get('https://github.com/vdorie/npci/raw/master/examples/ihdp_sim/data/ihdp.RData')\n",
    "open('input_data.RData', 'wb').write(res.content)\n",
    "ihdp = pyreadr.read_r('input_data.RData')['ihdp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42e5d48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data_sets(ihdp, seed, plot = False):\n",
    "    ihdpShuffled = ihdp.sample(frac = 1, random_state =  seed)\n",
    "\n",
    "    X = ihdp.loc[:, ihdp.columns != 'treat'].values\n",
    "\n",
    "    #Standardize X values\n",
    "    mu = np.mean(X, axis = 0)\n",
    "    sd = np.std(X, axis = 0)\n",
    "    X = ((X-mu)/sd)\n",
    "\n",
    "    t = ihdp.loc[:, ihdp.columns == 'treat'].values\n",
    "    y, y0, y1 = response_surface_B(t, X)\n",
    "\n",
    "    #train / valid / test splits: \n",
    "    N, D = X.shape\n",
    "    Ntrain = int(0.6 * N)\n",
    "    Nvalid = int(0.8 * N)\n",
    "\n",
    "    output = dict()\n",
    "    \n",
    "    output['X'] = [X[:Ntrain], X[Ntrain:Nvalid], X[Nvalid:]]\n",
    "    output['y'] = [y[:Ntrain], y[Ntrain:Nvalid], y[Nvalid:]]\n",
    "    output['t'] = [t[:Ntrain], t[Ntrain:Nvalid], t[Nvalid:]]\n",
    "    output['y0'] = [y0[:Ntrain], y0[Ntrain:Nvalid], y0[Nvalid:]]\n",
    "    output['y1'] = [y1[:Ntrain], y1[Ntrain:Nvalid], y1[Nvalid:]]\n",
    "    \n",
    "    if plot: \n",
    "        #plt.hist(y*t)\n",
    "        #plt.hist(y*(1-t))\n",
    "        sns.histplot(y[t==0], label = 'y | t = 0', color = 'blue')\n",
    "        sns.histplot(y[t==1], label = 'y | t = 1', color = 'green')\n",
    "        plt.legend()\n",
    "        print('Average for t=1: {}'.format(np.mean(t*y)))\n",
    "        print('Average for t=0: {}'.format(np.mean((1-t)*y)))\n",
    "        print('Average treatment effect: {}'.format(np.mean(t*y)- np.mean((1-t)*y)))\n",
    "        print('Average effect on treated (CATT): {}'.format(np.mean((y1-y0)*t)))\n",
    "    \n",
    "    return output, D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "93a6c362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average for t=1: -5.743027171851527\n",
      "Average for t=0: 5.636989313532902\n",
      "Average treatment effect: -11.380016485384429\n",
      "Average effect on treated (CATT): -9.485074403299825\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "datasets, D = generate_data_sets(ihdp, 42, plot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfab94e",
   "metadata": {},
   "source": [
    "## 4. Train and tune one model on each of the 10 datasets you have created.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a054e1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_batch(inputs, treatments, outcomes, batchSize):\n",
    "    # loop over the dataset\n",
    "    for i in range(0, inputs.shape[0], batchSize):\n",
    "        # yield a tuple of the current batched data and labels\n",
    "        yield (torch.from_numpy(inputs[i:i + batchSize].astype(np.float32)), \n",
    "               torch.from_numpy(treatments[i:i + batchSize].astype(np.float32)),\n",
    "               torch.from_numpy(outcomes[i:i + batchSize].astype(np.float32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4853ebd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, datasets, EPOCHS = 10, BATCH_SIZE = 64, LR=1e-3, VERBOSE = False):\n",
    "    Xtrain, Xvalid, Xtest = datasets['X']\n",
    "    ytrain, yvalid, ytest = datasets['y']\n",
    "    ttrain, tvalid, ttest = datasets['t']\n",
    "    \n",
    "    opt = SGD(model.parameters(), lr=LR)\n",
    "    model_performance = []\n",
    "\n",
    "    # loop through the epochs\n",
    "    for epoch in range(0, EPOCHS):\n",
    "        # initialize tracker variables and set our model to trainable\n",
    "        if VERBOSE: print(\"[INFO] epoch: {}...\".format(epoch + 1))\n",
    "        trainLoss = 0\n",
    "        valLoss = 0\n",
    "        samples = 0\n",
    "        model.train()\n",
    "\n",
    "        # loop over the current batch of data\n",
    "        for (batchX, batcht, batchy) in next_batch(Xtrain, ttrain, ytrain, BATCH_SIZE):\n",
    "\n",
    "            # model, and calculate loss\n",
    "            predictions = model(batchX)\n",
    "            loss = lossFunc(batchy, batcht, predictions)\n",
    "\n",
    "            # zero the gradients accumulated from the previous steps,abs\n",
    "            # perform backpropagation, and update model parameters\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            # update training loss, accuracy, and the number of samples visited\n",
    "            trainLoss += loss.item()\n",
    "            samples += batchy.size(0)\n",
    "                \n",
    "        #Store model and validation error after each epoch: \n",
    "        PATH = \"model_checkpoints/model_state_epoch_\"+str(epoch)+\".pt\"\n",
    "        torch.save(model, PATH)\n",
    "    \n",
    "        predictions_valid = model(torch.from_numpy(Xvalid.astype(np.float32)))\n",
    "        valLoss = lossFunc(torch.from_numpy(yvalid.astype(np.float32)),\n",
    "                           torch.from_numpy(tvalid.astype(np.float32)),\n",
    "                           predictions_valid).detach().numpy()\n",
    "        model_performance.append(valLoss / yvalid.shape[0])\n",
    "\n",
    "        # display model progress on the training and validation data\n",
    "        trainTemplate = \"epoch: {} train loss: {:.3f} val loss {:.3f}\"\n",
    "        if VERBOSE: print(trainTemplate.format(epoch + 1, \n",
    "                                               (trainLoss / samples), \n",
    "                                               (valLoss / yvalid.shape[0])))\n",
    "            \n",
    "    #Load and return model with minimal validation error \n",
    "    best_epoch = np.argmin(model_performance)\n",
    "    print('Best epoch: {} Best val loss: {:.3f}'.format(best_epoch+1, model_performance[best_epoch]))\n",
    "    best_model_path = \"model_checkpoints/model_state_epoch_\"+str(best_epoch)+\".pt\"\n",
    "    best_model = torch.load(best_model_path)\n",
    "    best_model.eval()    \n",
    "    \n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef6e919",
   "metadata": {},
   "source": [
    "## 5. Report the mean and standard error of the Root Mean Average Precision in Heterogeneous Effect (described in the above papers) across the 10 held out test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a06a8538",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PEHE(y0_true, y1_true, predictions):\n",
    "    y0_hat = predictions[:,0].reshape(-1,1)\n",
    "    y1_hat = predictions[:,1].reshape(-1,1)\n",
    "    return torch.mean(((y1_true - y0_true)- (y1_hat - y0_hat))**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2614aad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1\n",
      "Best epoch: 100 Best val loss: 54.070\n",
      "Iteration: 2\n",
      "Best epoch: 100 Best val loss: 66.243\n",
      "Iteration: 3\n",
      "Best epoch: 74 Best val loss: 50.270\n",
      "Iteration: 4\n",
      "Best epoch: 84 Best val loss: 56.477\n",
      "Iteration: 5\n",
      "Best epoch: 100 Best val loss: 52.997\n",
      "Iteration: 6\n",
      "Best epoch: 88 Best val loss: 52.783\n",
      "Iteration: 7\n",
      "Best epoch: 100 Best val loss: 51.086\n",
      "Iteration: 8\n",
      "Best epoch: 37 Best val loss: 38.152\n",
      "Iteration: 9\n",
      "Best epoch: 67 Best val loss: 70.211\n",
      "Iteration: 10\n",
      "Best epoch: 100 Best val loss: 58.835\n",
      "************************\n",
      "Mean of Root PEHE: 7.872\n",
      "Standard Error of Root PEHE: 0.705\n"
     ]
    }
   ],
   "source": [
    "RootPEHE = []\n",
    "for i in range(10):\n",
    "    print('Iteration: {}'.format(i+1))\n",
    "    datasets, D = generate_data_sets(ihdp, 42+i, plot = False)\n",
    "    \n",
    "    model = TarNet(D)\n",
    "    model = train_model(model, \n",
    "                        datasets, \n",
    "                        EPOCHS = 100, \n",
    "                        BATCH_SIZE = 128,\n",
    "                        LR = 1e-5,\n",
    "                        VERBOSE = False)\n",
    "\n",
    "    #Calcualte mean and standard error of the Root Mean Average Precision on test data     \n",
    "    _, _, Xtest = datasets['X']\n",
    "    _, _, ytest = datasets['y']\n",
    "    _, _, ttest = datasets['t']\n",
    "    _, _, y0test = datasets['y0']\n",
    "    _, _, y1test = datasets['y1']\n",
    "    \n",
    "    predictions_test = model(torch.from_numpy(Xtest.astype(np.float32)))\n",
    "    \n",
    "    RootPEHE.append(torch.sqrt(PEHE(torch.from_numpy(y0test.astype(np.float32)), \n",
    "                                    torch.from_numpy(y1test.astype(np.float32)), \n",
    "                                    predictions_test)).detach().numpy())\n",
    "    \n",
    "print('************************')\n",
    "print('Mean of Root PEHE: {:.3f}'.format(np.nanmean(RootPEHE)))\n",
    "print('Standard Error of Root PEHE: {:.3f}'.format(np.std(RootPEHE)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
